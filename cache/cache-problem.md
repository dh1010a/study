# 캐시 문제 해결 가이드 - DB 과부하 방지 실전 팁
- 데이터 베이스는 시스템을 확장하기 어렵다. 주로 샤딩과 복제를 통해 어렵게 확장하는데 이 과정애서 일관성, 가용성, 분할 내성 모두 만족시킬 수 없다는 이론이 있다(CAP 이론).
- 데이터 베이스의 부하를 최소화 하여 확장 필요성을 줄이는 것이 좋은데, 이를 위한 기본적인 접근은 캐싱이다.
- 높은 캐시 히트율을 유지하면 데이터베이스를 확장 하지 않아도 많은 트래픽을 처리할 수 있다.
- Reids나 Memcached와 같은 인메모리 DB로 캐시 시스템을 많이 구축
- 사용하기 쉽고 응답 속도가 빠름

> CAP이론이란?
>
> 분산 시스템에서는 Consistency, Availability, Partition Tolerance 중 세 가지를 동시에 완벽하게 만족할 수 없다는 이론.
> - C	Consistency (일관성)	모든 노드가 같은 값을 본다 (DB 복제된 서버라도 데이터는 동일)
> - A	Availability (가용성)	항상 응답을 준다 (에러 없이 빠르게 결과를 돌려줌)
> - P	Partition Tolerance (분할 허용성)	네트워크가 나눠져도 시스템은 살아있다
>
> 분산 시스템은 네트워크로 연결되기 때문에,언제든지 노드 간 통신이 끊어질 수 있음
> 따라서 P는 무조건 유지해야만 함 → 그러면 남은 건 C vs A
>
> - CP: 시스템	일관성을 위해 가용성을 포기 → 네트워크가 불안하면 응답 안 줌
> - AP: 시스템	가용성을 위해 일관성 포기 → 결과는 틀릴 수 있지만 응답은 함
> - CA: 이론적으로 불가능 (네트워크 분할 안 생겨야 함)	단일 노드 시스템만 가능

## 1. 캐시 쇄도(Cache Stampede)
![image](https://github.com/user-attachments/assets/55e2d2a4-3205-46bc-8d4a-ee535b29c461)

- 캐시 미스가 동시에 많이 발생하면 DB 부하가 커짐.
- 캐시가 전부 정확히 같은 시간에 만료되도록 구현하면 자주 발생
- 매일 자정에 캐시를 갱신한다고 하면, 그 시간에 맞춰 캐시가 일제히 만료되도록 설계하는 것은 쉽고 최신 정보를 바로 제공할 수 있음
- 캐시가 만료되는 자정마다 데이터베이스로 트래픽이 집중되어 서비스 장애가 발생할 위험

### 해결법 : 지터(Jitter)
- 전자공학에서 사용되는 '지터(Jitter)' 개념을 활용.
- 지터는 전자 신호를 읽는 과정에서 발생하는 짧은 지연 시간을 의미
- 지터처럼 짧은 시간을 캐시 만료 시간에 더해서 부하를 분산시킬 수 있다
- 예를 들어 0~10초 사이의 무작위 지연 시간을 추가하면, DB 부하가 10초에 걸쳐 분산
- 서비스마다 허용할 수 있는 지연 시간은 다르기 때문에, 서비스에 적절한 최대 지터 시간을 설정
- 지터가 길어질수록 사용자는 더 오래된 정보를 볼 수 있으므로, 지터가 과도하게 추가되지 않도록 주의

## 2. 캐시 관통(Cache Penetration)
![image](https://github.com/user-attachments/assets/70e4009b-c880-4f1a-a28e-5dec27f93646)

- 보통 캐시에서 null 값이 반환되면 DB를 조회해서 캐시를 채움
- DB를 해당 값이 없어서 null을 반환받았을 때는 캐시를 채우지 않도록 보통 구현
- DB로 부터 반환받은 '값이 없다'라는 정보를 캐싱하지 않으면 위험 발생 가능
- 이렇게 DB에서 읽었는데도 캐싱 되지 않는 상황을 캐시 관통이라고 함
- 캐시 관통이 빈번하다면, DB에 불필요한 조회 요청이 자주 발생
- 따라서 데이터가 없다는 사실도 캐싱해야 불필요한 데이터베이스 부하를 줄일 수 있다

### 해결안: 널 오브젝트 패턴(Null Object Pattern)
- 값이 없다는 것을 캐싱함으로써 D의 트래픽을 줄이려면 블룸 필터를 사용하는 것도 좋은 방법
- 블룸 필터를 사용하면 확률적으로 캐시 관통을 방지
- 블룸 필터의 정합성이 깨진다면, 블룸 필터를 복구하기 위해 모든 캐시를 읽어야 해서 운영이 어려움
- 널 오브젝트 패턴을 사용해서 ‘값이 없음’을 캐싱하는 방법이 운영하기 더 쉽다
- 객체 타입은 부재를 뜻하는 객체를 선언하여 사용하면 되지만, 원시 타입은 이 객체를 대체할 특정 값을 지정해야 함
- 예를 들어, 양수만 존재하는 정수 타입의 데이터를 캐시할 때는 음수인 정수의 최솟값으로 값이 없음을 나타내기로 정할 수 있음

## 3. 캐시 시스템 장애
![image](https://github.com/user-attachments/assets/92127928-e51a-4fbd-af50-38b222245da1)

- 보통 상황에서는 캐시 시스템에 장애가 발생하더라도 DB로 트래픽을 보내면 서비스를 정상 운영할 수 있음
- 트래픽이 큰 상황이라면 캐시 시스템이 복구될 때까지 DB에 과부하가 걸릴 수 있음
- DB가 모든 트래픽을 감당할 수 있다고 낙관하면 안 됨
- DB가 한계를 넘는 트래픽을 받으면, 캐시와 무관한 기능조차 정상적으로 작동하지 못할 수 있음
- 따라서 DB가 감당할 수 있는 범위의 트래픽을 유지하도록 해야함

### 해결안: 대체 작동(Failover)
- 캐시 시스템이 망가졌다면 반드시 동작해야 되는 핵심 기능을 제외하고 부가 기능은 일시적으로 운영을 중단하는 게 좋음
- 캐시 시스템이 복구되는 동안 DB가 핵심 기능으로 트래픽을 처리할 수 있고, 부가 기능은 사용자에게 대체 UI를 제공하거나 양해를 구하는 게 현실적인 대응 방법
- 캐시 코드를 공통화 하다보면 기능의 중요도를 따지지 않고, DB로 fallback하는 코드를 작성하기 쉬움
- 데이터베이스 부하를 감안하더라도 꼭 동작해야할 기능인지 미리 고민

## 4. 핫(Hotkey) 만료
![image](https://github.com/user-attachments/assets/d0d0295d-4073-4f4d-9f45-48c75bcd7434)

- 많은 요청이 집중되는 키를 핫키라고 함
- 핫키가 만료되는 순간, 여러 요청이 동시에 DB를 반복 조회할 수 있음
- 캐시의 만료 기한을 없애거나, 백그라운드에서 주기적으로 새 값을 적용해서 캐시가 만료되지 않도록 하는게 좋음
- 핫키가 때에 따라 바뀌는 환경에서는 더 이상 핫키가 아닌 데이터로 인해 캐시 저장소 공간이 낭비될 수 있음

### 해결안: 분산 락(Distributed Lock)
- 분산 락을 사용하면 공간 낭비 없이 불필요한 DB 중복 조회를 방지할 수 있음
- 멀티 스레드 프로그래밍에서 공유 자원 다룰 때 락을 사용하는 것과 비슷한 원리
- 캐시를 애플리케이션 서버 간의 공유 자원으로 볼 수 있음
- 캐시 미스가 발생했을 때 락을 설정하고 캐싱한 후에 락을 해제함으로써, 단 한 번의 쓰기 작업만 허용할 수 있음
- Redis를 사용하고 있다면 분산 락을 적용하기 굉장히 쉬움
- Redis의 싱글 스레드 특징을 활용한 레드락 알고리즘을 활용
- 분산 환경에서도 공유 자원을 효과적으로 관리할 수 있음
- 분산 락을 구현할 방법은 다양함. 핫키 만료 상황에서 분산 락을 이용하면 캐시 히트율을 유지할 수 있음

## 정리
- DB와 캐시 시스템의 상호작용은 예측하기 어려움
- 제시된 아이디어를 실제로 적용할 때는 더 다양한 요소들을 고려해야 함


## Reference
- https://toss.tech/article/cache-traffic-tip
